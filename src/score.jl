"""
    entropy(J::AbstractMatrix)
    entropy(belief::AbstractBelief)

Entropy value for a multivariate Gaussian with positive-definite precision `J`.

The second version applies the first version to the precision of `belief` (i.e.
`belief.J`, which must be positive definite). 

See implementation in [Distributions.jl](https://github.com/JuliaStats/Distributions.jl/blob/e407fa5fd098e50df51801c6d062946eac7a7d0f/src/multivariate/mvnormal.jl#L95).
"""
function entropy(J::AbstractMatrix)
    0.5*(size(J,2) * (log2œÄ + 1) - LA.logdet(LA.cholesky(J)))
end
function entropy(cluster::AbstractBelief)
    entropy(cluster.J)
end

"""
    average_energy(ref::Tuple, target::Tuple, dropg::Bool=false)
    average_energy(ref::AbstractBelief, target::AbstractBelief, dropg::Bool=false)
    average_energy(ref::AbstractBelief, target::Tuple, dropg::Bool=false)

Average energy (i.e. negative expected log) of a `target` canonical form with
parameters `(J‚Çú, h‚Çú, g‚Çú)` with respect to a normalized non-degenerate reference
(`ref`) canonical form with parameters `(J·µ£, h·µ£)` (specifying `g·µ£` is
unnecessary to compute this quantity). When the target canonical form is also
normalized and non-degenerate, this is equal to their cross-entropy. If
`dropg=true`, then average energy is computed assuming that `g‚Çú=0`.

## Calculation:
    `ref`: f(x) = C(J·µ£, h·µ£, _) ‚â° x ~ ùí©(Œº=J·µ£‚Åª¬πh·µ£, Œ£=J·µ£‚Åª¬π)
    `target`: C(J‚Çú, h‚Çú, g‚Çú)

        E[-log C(J‚Çú, h‚Çú, g‚Çú)]
    = E[(1/2)x'*J‚Çú*x - h‚Çú'x - g‚Çú)] where x ‚àº C(J·µ£, h·µ£, _)
    = (1/2)*(Œº·µ£'*J‚Çú*Œº·µ£ + tr(J‚Çú*J·µ£‚Åª¬π)) - h‚Çú'*Œº·µ£ - g‚Çú
    = (1/2)*(tr(J‚Çú*Œº·µ£*Œº·µ£') + tr(J‚Çú*J·µ£‚Åª¬π)) - h‚Çú'*Œº·µ£ - g‚Çú

The second version takes two possible beliefs (`ref`, `target`) for a given
cluster/sepset and computes the average energy of `target` with respect to `ref`
by applying the first version to their canonical parameters. `ref` is assumed to
be non-degenerate (i.e. `J·µ£` is positive-definite).

The third version is similar to the second one, except that `target` is specified
by its canonical parameters.
"""
function average_energy(refcanon::Tuple{AbstractMatrix{T}, AbstractVector{T}},
    targetcanon::Tuple{AbstractMatrix{T}, AbstractVector{T}, T}, 
    dropg::Bool=false) where T <: AbstractFloat
    J·µ£ = LA.cholesky(refcanon[1])
    Œº·µ£ = J·µ£ \ refcanon[2]
    (J‚Çú, h‚Çú, g‚Çú) = targetcanon
    # fixit: check for more efficient order of operations
    if dropg g‚Çú = 0.0 end
    0.5*LA.tr(J‚Çú*(Œº·µ£*Œº·µ£' + LA.inv(J·µ£))) - h‚Çú'*Œº·µ£ - g‚Çú
end
average_energy(reference::AbstractBelief, target::AbstractBelief,
    drop::Bool=false) = average_energy((reference.J, reference.h),
        (target.J, target.h, target.g[1]), drop)
average_energy(reference::AbstractBelief,
    targetcanon::Tuple{AbstractMatrix, AbstractVector, AbstractFloat},
    drop::Bool=false) = average_energy((reference.J, reference.h),
        targetcanon, drop)

"""
    free_energy(beliefs::ClusterGraphBelief)

Bethe free energy from `beliefs`. This is computed by adding up cluster average
energies and entropies, and subtracting sepset entropies. It is assumed but not
checked that `beliefs` are calibrated.

For a calibrated clique tree, -(Bethe free energy) is equal to the
log-likelihood. For a calibrated cluster graph, -(Bethe free energy) approximates
the evidence lower bound (ELBO) for the log-likelihood. Thus, minimizing the
Bethe free energy maximizes an approximation to the ELBO for the log-likelihood.

See also: [`entropy`](@ref), [`average_energy`](@ref), [`iscalibrated`](@ref)

## References
D. M. Blei, A. Kucukelbir, and J. D. McAuliffe. Variational inference: A Review
for Statisticians, Journal of the American statistical Association, 112:518,
859-877, 2017, doi: [10.1080/01621459.2017.1285773](https://doi/org/10.1080/01621459.2017.1285773).
"""
function free_energy(beliefs::ClusterGraphBelief)
    b = beliefs.belief
    init_b = beliefs.factors
    nbeliefs = length(b)
    nclusters = beliefs.nclusters
    ave_energy = 0.0
    approx_entropy = 0.0
    for i in 1:nclusters
        ave_energy += average_energy(b[i], init_b[i])
        approx_entropy += entropy(b[i])
    end
    for i in (nclusters+1):nbeliefs
        approx_entropy -= entropy(b[i])
    end
    return (ave_energy, approx_entropy, ave_energy - approx_entropy)
end